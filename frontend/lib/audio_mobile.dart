import 'audio_control.dart';
import 'dart:async';
import 'dart:convert';
import 'package:flutter/foundation.dart';
import 'dart:math';
import 'package:record/record.dart'; // package:record ì‚¬ìš©
import 'package:permission_handler/permission_handler.dart'; // ê¶Œí•œ ê´€ë¦¬

typedef OnAudioDataReady = void Function(String audioJson);
typedef OnRecordingStateChanged = void Function(bool isRecording);

class AudioImpl extends AudioControl {
  // ëª¨ë°”ì¼ ë…¹ìŒê¸° ì¸ìŠ¤í„´ìŠ¤
  final AudioRecorder _audioRecorder = AudioRecorder();
  StreamSubscription<List<int>>? _recordSub;

  // ì˜¤ë””ì˜¤ ë°ì´í„° ë²„í¼ (PCM 16bit ë°ì´í„°ë¥¼ ëª¨ìœ¼ê¸° ìœ„í•¨)
  final List<int> _audioBytesBuffer = [];

  bool _isRecording = false;
  double _audioLevel = 0.0;

  // ì¹¨ë¬µ ê°ì§€ ê´€ë ¨
  late Duration _silenceDuration;
  final double _silenceThreshold = 0.05; // ëª¨ë°”ì¼ ë§ˆì´í¬ ê°ë„ì— ë”°ë¼ ì¡°ì ˆ í•„ìš”
  final Duration _silenceDurationLimit = const Duration(seconds: 2);
  Timer? _silenceTimer;

  OnAudioDataReady? _onAudioDataReady;
  OnRecordingStateChanged? _onRecordingStateChanged;

  AudioMobile({
    OnAudioDataReady? onAudioDataReady,
    OnRecordingStateChanged? onRecordingStateChanged,
  }) {
    _onAudioDataReady = onAudioDataReady;
    _onRecordingStateChanged = onRecordingStateChanged;
  }

  @override
  double get audioLevel => _audioLevel;

  // AudioControlImpl({onAudioDataReady, onRecordingStateChanged}) {
  //   _onAudioDataReady = onAudioDataReady;
  //   _onRecordingStateChanged = onRecordingStateChanged;
  // }

  @override
  Future<bool> requestPermission() async {
    // Permission Handler ì‚¬ìš©
    var status = await Permission.microphone.request();
    if (status.isGranted) {
      debugPrint('Microphone access granted');
      return true;
    } else {
      debugPrint('Microphone access denied');
      return false;
    }
  }

  @override
  Future<void> startRecording() async {
    if (_isRecording) return;

    // ê¶Œí•œ ì¬í™•ì¸
    if (!await _audioRecorder.hasPermission()) {
      debugPrint('âŒ No permission to record');
      return;
    }

    try {
      _isRecording = true;
      _audioBytesBuffer.clear();
      _silenceDuration = Duration.zero;
      _audioLevel = 0.0;

      debugPrint('â–¶ï¸ Started Mobile Recording');
      notifyListeners();

      // ìŠ¤íŠ¸ë¦¼ ì‹œì‘ (PCM 16bit, 16000Hz, Mono ê¶Œì¥ - STT ì„œë²„ ìŠ¤í™ì— ë§ì¶¤)
      final stream = await _audioRecorder.startStream(
        const RecordConfig(
          encoder: AudioEncoder.wav,
          sampleRate: 16000,
          numChannels: 1,
        ),
      );

      _recordSub = stream.listen((data) {
        // 1. ë°ì´í„° ë²„í¼ì— ì €ì¥
        _audioBytesBuffer.addAll(data);

        // 2. ì‹¤ì‹œê°„ ë³¼ë¥¨ ë¶„ì„
        _analyzeAudioLevel(data);
      });

      // ì¹¨ë¬µ ê°ì§€ íƒ€ì´ë¨¸ ì‹œì‘ (0.1ì´ˆë§ˆë‹¤ ì²´í¬)
      _silenceTimer = Timer.periodic(const Duration(milliseconds: 100), (
        timer,
      ) {
        _checkSilence();
      });

      _onRecordingStateChanged?.call(true);
    } catch (e) {
      debugPrint("âŒ Error starting record: $e");
      _isRecording = false;
    }
  }

  // ë“¤ì–´ì˜¤ëŠ” PCM ë°ì´í„° ë©ì–´ë¦¬ë¥¼ ë¶„ì„í•˜ì—¬ ë³¼ë¥¨ ê³„ì‚°
  void _analyzeAudioLevel(List<int> data) {
    // PCM 16bitëŠ” 2ë°”ì´íŠ¸ê°€ 1ê°œì˜ ìƒ˜í”Œ (-32768 ~ 32767)
    // ë°ì´í„°ê°€ ë„ˆë¬´ ë§ìœ¼ë¯€ë¡œ ì¼ë¶€ë§Œ ìƒ˜í”Œë§í•˜ì—¬ ê³„ì‚° (ì„±ëŠ¥ ìµœì í™”)
    double sumSquares = 0.0;
    int sampleCount = 0;

    for (int i = 0; i < data.length; i += 2) {
      if (i + 1 >= data.length) break;

      // Little Endian ë³€í™˜
      int byte1 = data[i];
      int byte2 = data[i + 1];
      int s16 = (byte2 << 8) | byte1;

      // ë¶€í˜¸ ìˆëŠ” 16ë¹„íŠ¸ ì •ìˆ˜ë¡œ ë³€í™˜
      if (s16 > 32767) s16 -= 65536;

      // -1.0 ~ 1.0 ì •ê·œí™”
      double normalized = s16 / 32768.0;
      sumSquares += normalized * normalized;
      sampleCount++;
    }

    if (sampleCount > 0) {
      // RMS (Root Mean Square) ê³„ì‚°
      double rms = sqrt(sumSquares / sampleCount);

      // ìŠ¤ë¬´ë”© ì ìš©
      _audioLevel = (_audioLevel * 0.7) + (rms * 0.3);
      notifyListeners();
    }
  }

  void _checkSilence() {
    if (!_isRecording) return;

    if (_audioLevel < _silenceThreshold) {
      _silenceDuration += const Duration(milliseconds: 100);
      if (_silenceDuration >= _silenceDurationLimit) {
        debugPrint('ğŸ”‡ Silence detected on Mobile. Auto-stopping...');
        _stopTransmitting();
      }
    } else {
      _silenceDuration = Duration.zero;
    }
  }

  Future<void> _stopTransmitting() async {
    if (!_isRecording) return;

    final wavBytes = await stopRecording();
    final base64Wav = base64Encode(wavBytes);

    debugPrint('Encoded Audio Length: ${base64Wav.length}');

    final audioJson = jsonEncode({
      'command': 'transcribe',
      'audio': base64Wav,
      "target_lang1": getSpeaker1, // AudioControlì˜ getter
      "target_lang2": getSpeaker2, // AudioControlì˜ getter
    });

    _onAudioDataReady?.call(audioJson);
    notifyListeners();
  }

  @override
  Future<Uint8List> stopRecording() async {
    _isRecording = false;
    _silenceTimer?.cancel();
    await _recordSub?.cancel();
    await _audioRecorder.stop(); // ìŠ¤íŠ¸ë¦¼ ì¤‘ì§€

    debugPrint('â¹ï¸ Stopped mobile recording');

    _onRecordingStateChanged?.call(false);
    notifyListeners();

    // Raw PCM ë°ì´í„°ë¥¼ WAV í¬ë§·ìœ¼ë¡œ ë³€í™˜ (í—¤ë” ì¶”ê°€)
    return _pcmToWav(Uint8List.fromList(_audioBytesBuffer));
  }

  @override
  void dispose() {
    _silenceTimer?.cancel();
    _recordSub?.cancel();
    _audioRecorder.dispose();
  }

  Uint8List _pcmToWav(Uint8List pcmBytes) {
    final int sampleRate = 16000;
    final int channels = 1;
    final int byteRate = sampleRate * channels * 2; // 16bit = 2bytes

    final header = ByteData(44);
    final totalDataLen = pcmBytes.length;
    final totalFileSize = totalDataLen + 36;

    // RIFF header
    _writeString(header, 0, 'RIFF');
    header.setUint32(4, totalFileSize, Endian.little);
    _writeString(header, 8, 'WAVE');

    // fmt chunk
    _writeString(header, 12, 'fmt ');
    header.setUint32(16, 16, Endian.little); // PCM chunk size
    header.setUint16(20, 1, Endian.little); // Audio format 1 (PCM)
    header.setUint16(22, channels, Endian.little);
    header.setUint32(24, sampleRate, Endian.little);
    header.setUint32(28, byteRate, Endian.little);
    header.setUint16(32, channels * 2, Endian.little); // Block align
    header.setUint16(34, 16, Endian.little); // Bits per sample

    // data chunk
    _writeString(header, 36, 'data');
    header.setUint32(40, totalDataLen, Endian.little);

    final wavBytes = Uint8List(44 + pcmBytes.length);
    wavBytes.setRange(0, 44, header.buffer.asUint8List());
    wavBytes.setRange(44, 44 + pcmBytes.length, pcmBytes);

    return wavBytes;
  }

  void _writeString(ByteData data, int offset, String value) {
    for (int i = 0; i < value.length; i++) {
      data.setUint8(offset + i, value.codeUnitAt(i));
    }
  }
}
